{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning in Medicine - Spring 2019\n",
    "### BMSC-GA 4493, BMIN-GA 3007 \n",
    "### Homework 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note:** If you need to write mathematical terms, you can type your answeres in a Markdown Cell via LaTex \n",
    "\n",
    "See: <a href=\"https://stackoverflow.com/questions/13208286/how-to-write-latex-in-ipython-notebook\">here</a> if you have issues. To see basic LaTex notation see: <a href=\"https://en.wikibooks.org/wiki/LaTeX/Mathematics\"> here </a>.\n",
    "\n",
    "**Submission instruction**: Upload and Submit your final jupyter notebook with necessary files in <a href='http://newclasses.nyu.edu'>newclasses.nyu.edu</a>. If you use code or script from web, please give a link to the code in your answers. Not providing the reference of the code used will reduce your points!!\n",
    "\n",
    "**Submission deadline:** Friday March 29th 2019 (5:00 PM) --> No Extensions!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1: Convolutional Layer  (Total 20 points)\n",
    "\n",
    "We have a 2x6x6 image (2 channels) and three 2x3x3 convolution kernels as pictured. Bias term for each feature map is also provided. For the questions below, please provide the feature/activation maps requested, please provide the python code that you used to calculate the maps\n",
    "\n",
    "<img src=\"Picture1.png\" width=\"900\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1) \n",
    "What will be the dimension of the feature maps after we forward propogate the image using the given convolution kernels for"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.a) (1 point)\n",
    "stride=1, without zero padding?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.b) (1 point)\n",
    "stride=2, without zero padding?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.c) (1 point) \n",
    "stride=2, with zero padding?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.d) (1 point)\n",
    "stride=3, with zero padding?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1.e) (1 point) \n",
    "a dilated convolution with stride=1, dilation rate=2 and zero padding?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2) (5 points)\n",
    "Use the pytorch package to calculate feature/activation maps. Write a code which takes 2x6x6 image and performs a 2D convolution operation (with stride=2 and no zero padding) using 2x3x3 filters provided on the picture. After convolution layer use leaky ReLU activation function (with negative slope 0.01) and L2-pooling operation (pool width = 2 and stride = 1). Provide the code, feature maps obtained from convolution operation, activation maps, and feature maps after L2-pooling operation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# starter code to load image:x, kernel weights:w and bias:b\n",
    "import numpy as np\n",
    "npzfile = np.load('Question1p2.npz') # 'Question1p2.npz' is provided in github repo\n",
    "print(npzfile.files) # check the variable names\n",
    "x = npzfile['x']\n",
    "w = npzfile['w']\n",
    "b = npzfile['b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3) (10 points)\n",
    "Use the pytorch package to calculate feature/activation maps of a residual unit as depicted in Figure 2 of https://arxiv.org/pdf/1512.03385.pdf as well as on the figure above.\n",
    "\n",
    "Input --> Convolution --> Activation --> Convolution --> Addition --> Activation\n",
    "\n",
    "Write a code which takes 2x6x6 image and performs two 2D convolution operations (stride = 1, dilation rate = 2 ) using first two 2x3x3 filters provided on the figure. After the first convolution layer and after the addition use ReLU activation function. Provide the code and feature maps obtained from each convolution operation, activation maps, and the last activation map obtained from the residual unit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2: Network design parameters for disease classification (Total 15 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Disease classification is a common problem in medicine. There are many ways to solve this problem. Goal of this question is to make sure that you have a clear picture in your mind about possible techniques that you can use in such a classification task.\n",
    "\n",
    "Assume that we have a 10K brain images in a dataset of magnetic resonance images (MRIs). For each image, the dimension is 64x64x64 and we have the label for each image. The label of each image defines which class the image belongs (lets assume we have 3 different disease classes in total). You will describe your approach of classifying the disease for the techniques below. Make sure you do not forget the bias term. You can either design your proposed network by explaining it explicitely or you can provide the pytorch code which designs the network for questions 2.1.a, 2.2.a, and 2.3.a\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# starter code\n",
    "# you can generate a random image tensor for batch_size 8\n",
    "x = torch.Tensor(8,1,64,64,64).normal_().type(torch.FloatTensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.a) (2 points)\n",
    "Design a multi layer perceptron (MLP) with a single hidden layer which takes an image as input (by reshaping it to a vector: lets call this a vectorized image) and first maps the vectorized images to a vector of 128 then feeds this vector to a fully connected layer to get the probability of 3 tissue classes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.b) (2 points)\n",
    "Clearly mention the sizes for your input and output at each layer until you get final output vector with 3 tissue classes in 64x64x64 voxels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.c) (1 points)\n",
    "How many parameters you need to fit for your design? How does adding another hidden layer effected the number of parameters to use?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.a) (2 points)\n",
    "Design a one layer convolutional neural network which first maps the images to a vector of 128 (with the help of convolution and pooling operations) then feeds this vector to a fully connected layer to get the probability of 3 disease classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.b) (2 points)\n",
    "Clearly mention the sizes for your input, kernel, pooling, and output at each step until you get final output vector with 3 probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.c) (1 points) \n",
    "How many parameters you need to fit for your design?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.d) (2 points)\n",
    "Now increase your selected convolution kernel size by 4 in each direction. Describe the effect of using small vs large filter size during convolution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3) (3 points)\n",
    "Explain your findings regading different types of neural networks and building blocks based on your observations from 2.1 and 2.2. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3: Literature Review: ChestX-ray8 (Total 15 points + 3 points for Bonus question)\n",
    "Read this paper:\n",
    "\n",
    "Wang X, Peng T, Lu L, et al. \n",
    "ChestX-Ray8: Hospital-Scale Chest X-Ray Database and Benchmarks on Weakly-Supervised Classification and Localization of Common Thorax Diseases. CVPR. 2017. https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8099852\n",
    "\n",
    "\n",
    "We are interested in understanding the task, the methods that is proposed in this publication, technical aspects of the implementation, and possible future work. After you read the full article answer the following questions. Describe you answers in your own words.  \n",
    "\n",
    "## 3.1) (3 points) \n",
    "What type of learning algorithm is used (supervised, semi-supervised or unsupervised) for the classification and localization tasks? What is the reason for selecting this type of learning algorithm? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2) (5 points)\n",
    "What type of convolutional neural network architectures were used in the paper? How does transfer learning from these architectures achieved?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.3) (2 points)\n",
    "What is the loss function? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.4) (5 points)\n",
    "\n",
    "What are the evaluation metrics used for model comparison in classification and localization task? Explain why those metrics were chosen?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.5) Bonus (3 points)\n",
    "Why did the authors perform text mining?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Question 4: Deep CNN design for disease classification (Total 30 points)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this part of the howework, we will focus on classifiying the lung disease using chest x-ray dataset provided by NIH (https://www.nih.gov/news-events/news-releases/nih-clinical-center-provides-one-largest-publicly-available-chest-x-ray-datasets-scientific-community). You should be familiar with the dataset after answering Question 3.\n",
    "\n",
    "You need to use HPC for training part of this question, as your computer's CPU will not be fast enough to compute learning iterations. In case you use HPC, please have your code/scripts uploaded under the questions and provide the required plots and tables there as well. Data is available in HPC under /beegfs/ga4493/data/HW2 folder. We are interested in distinguishing between only pneumothorax and only cardiomegaly cases. By saying so we have 2 classes that we want to identify by modelling a deep CNN.\n",
    "\n",
    "First, you need to work on Data_Entry_2017.csv file to identify cases/images that has only pneumothorax and only cardiomegaly. This file can be downloaded from https://nihcc.app.box.com/v/ChestXray-NIHCC\n",
    "\n",
    "## 4.1) Train, Test, and Validation Sets (2 points)\n",
    "Write a script to read data from Data_Entry_2017.csv and process to obtain 3 sets (train, validation and test). By using 'Finding Labels' column, define a class that each image belongs to, in total you can define 2 classes:\n",
    "- 0 cardiomegaly\n",
    "- 1 pneumothorax\n",
    "\n",
    "Generate a train, validation and test set by splitting the whole dataset containing specific classes (0, and 1)  by 70%, 10% and 20%, respectively. Test set will not be used during modelling but it will be used to test your model's accuracy. Make sure you have similar percentages of different cases in each subset. Provide statistics of the number of classess in your subsets. (you do not need to think about splitting the sets based on subjects for this homework. In general, we do not want images from the same subject to appear in both train and test sets!!) \n",
    "\n",
    "Write a .csv files defining the samples in your train, validation and test set with names: train.csv, validation.csv, and test.csv. Submit these files with your homework. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2) Data preparation before training\n",
    "From here on, you will use HW2_trainSet.csv, HW2_testSet.csv and HW2_validationSet.csv provided under github repo for defining train, test and validation set samples instead of the csv files you generate on Question 4.1.\n",
    "\n",
    "\n",
    "There are multiple ways of using images as an input during training or validation. Here, you will use torch Dataset class  (http://pytorch.org/tutorials/beginner/data_loading_tutorial.html). We provided the dataloader code below. Please explain what does following lines of code achieves in the data loader and propose alternatives."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.a) (2 points) \n",
    "\n",
    "image = io.imread(img_name,as_gray=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.b) (2 points) \n",
    "\n",
    "image = (image - image.mean()) / image.std()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import os\n",
    "from skimage import io\n",
    "import torch\n",
    "from skimage import color\n",
    "\n",
    "class ChestXrayDataset(Dataset):\n",
    "    \"\"\"Chest X-ray dataset from https://nihcc.app.box.com/v/ChestXray-NIHCC.\"\"\"\n",
    "\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file filename information.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.data_frame = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.root_dir,\n",
    "                                self.data_frame.iloc[idx, 0])\n",
    "\n",
    "        image = io.imread(img_name,as_gray=True)\n",
    "        \n",
    "        image = (image - image.mean()) / image.std()\n",
    "            \n",
    "        image_class = self.data_frame.iloc[idx, -1]\n",
    "\n",
    "        sample = {'x': image[None,:], 'y': image_class}\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3) CNN model definition (6 points)\n",
    "Since now we can import images for model training, next step is to define a CNN model that you will use to train disease classification task. Any model requires us to select model parameters like how many layers, what is the kernel size, how many feature maps and so on. The number of possible models is infinite, but we need to make some design choices to start.  Lets design a CNN model with 2 convolutional layers, 2 residual units (similar to Figure 2 of https://arxiv.org/pdf/1512.03385.pdf) and a fully connected layer followed by a classification layer. Lets use \n",
    "\n",
    "-  3x3 convolution kernels (stride 1 in resnet units and stride 2 in convolutional layers)\n",
    "-  ReLU for an activation function\n",
    "-  max pooling with kernel 2x2 and stride 2 only after the convolutional layers. \n",
    "\n",
    "Define the number of feature maps in hidden layers as: 16, 16, 16, 32, 32, 32, 64 (1st layer, ..., 7th layer). \n",
    "\n",
    "Input --> Convolution1 --> ResNetBlock1 --> Convolution2 --> ResNetBlock2 --> FC --> Output\n",
    "\n",
    "\n",
    "Write a class which specifies this network details. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.4) (2 points)\n",
    "How many learnable parameters of this model has? How many learnable parameters we would have if we replace the fully connected layer with global average pooling layer (Take a look at Section 3.2 of https://arxiv.org/pdf/1312.4400.pdf)?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## 4.5) Loss function and optimizer (2 points)\n",
    "Define a loss criterion and an optimizer using pytorch. What type of loss function is applicable to our binary classification problem? Explain your choice of a loss function.  For an optimizer lets use SGD with momentum for now. Choose an emprical learning rate and momentum.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "_Some background:_ In network architecture design, we want to have an architecture that has enough capacity to learn. We can achive this by using large number of feature maps and/or many more connections and activation nodes. However, having a large number of learnable parameters can easily result in overfitting. To mitigate overfitting, we can keep the number of learnable parameters of the network small either using shallow networks or few feature maps. This approach results in underfitting that model can neither model the training data nor generalize to new data. Ideally, we want to select a model at the sweet spot between underfitting and overfitting. It is hard to find the exact sweet spot. \n",
    "\n",
    "We first need to make sure we have enough capacity to learn, without a capacity we will underfit. Here, you will need to check if designed model in 4.3. can learn or not. Since we do not need to check the generalization capacity (overfitting is OK for now since it shows learning is possible), it is a great strategy to use a subset of training samples. Also, using a subset of samples is helpful for debugging!!!\n",
    "\n",
    "## 4.6) Train the network on a subset (8 points)\n",
    "Lets use a script to take random samples from train set (HW2_trainSet.csv), lets name this set as HW2_randomTrainSet. Choose random samples from validation set (HW2_validationSet.csv), lets name this set as HW2_randomValidationSet. You used downsampling of images from 1024x1024 size to 64x64 in the Lab 4. This was fine for learning purpose but it will significantly reduce the infomation content of the images which is important especially in medicine. In this Howmework you MUST use original images of size 1024x1024 as the network input. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get samples from HW2_trainSet.csv\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "df = pd.read_csv('HW2_trainSet.csv')\n",
    "_ , X_random, _, _ = train_test_split(df, df.Class, test_size=0.1, random_state=0)\n",
    "print('Selected subset class frequencies\\n',X_random['Class'].value_counts())\n",
    "X_random.to_csv('HW2_randomTrainSet.csv',index=False)\n",
    "\n",
    "df = pd.read_csv('HW2_validationSet.csv')\n",
    "_ , X_random, _, _ = train_test_split(df, df.Class, test_size=0.1, random_state=0)\n",
    "print('Selected subset class frequencies\\n',X_random['Class'].value_counts())\n",
    "X_random.to_csv('HW2_randomValidationSet.csv',index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the random samples generated and write a script to train your network. Using the script train your network using your choice of weight initialization strategy. In case you need to define other hyperparameters choose them emprically, for example batch size. Plot average loss on your random sample set per epoch. (Stop the training after at most ~100 epochs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.7) Analysis of training using a CNN model(2 points)\n",
    "Describe your findings. Can your network learn from 230 random samples? Does CNN model have enough capacity to learn with your choice of emprical hyperparameters?\n",
    "-  If yes, how will average loss plot will change if you multiply the learning rate by 10?\n",
    "-  If no, how can you increase the model capacity? Increase your model capacity and train again until you find a model with enough capacity. If the capacity increase is not sufficient to learn, think about emprical parameters you choose in designing your network and make some changes on your selection. Describe what type of changes you made to your original network and how can you manage this model to learn."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.8) Train the network on the whole dataset (4 points)\n",
    "After question 4.7., you should have a network which has enough capacity to learn and you were able to debug your training code so that it is now ready to be trained on the whole dataset. Train your network on the whole train set (HW2_trainSet.csv) and check the validation loss on the whole validation set (HW2_validationSet.csv) in each epoch. Plot average loss and accuracy on train and validation sets. Describe your findings. Do you see overfitting or underfitting to train set? What else you can do to mitigate it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Transfer learning as a feature extractor (Total 12 points)\n",
    "In this part of the HW we are interested in using transfer learning for the disease classification task. we will use ResNet34 model to achieve this goal. Here is the link for the ResNet paper: https://arxiv.org/pdf/1512.03385.pdf  There are multiple ways of achieving transfer learning from a pretrained network as we cover in Lecture 6. You will use ResNet34 model pretrained on ImageNet as a fixed feature extractor in this question."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1)\n",
    "We need to make necessary changes in dataloader which is defined in Q.4.2. to make the dataset class is capable of feeding the X-ray dataset into resnet model for transfer learning. Remember X-ray data has grayscale images of 1024x1024 pixels and resnet34 model was trained on RGB images of size 256x256 from ImageNet. We provide you the new dataset class tailored for transfer learning. Answer the following questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1.a) (1 point)\n",
    "Please explain what does following lines of code would achievein the data loader?\n",
    "\n",
    "...\n",
    "\n",
    "transforms.Resize([256,256]),\n",
    "\n",
    "transforms.RandomResizedCrop(224),\n",
    "\n",
    "..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1.b) (2 points)\n",
    "Why do we need different transforms for train set and validation/test sets?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.1.c) (1 point)\n",
    "Please explain what does following line of code achieves in the data loader and propose alternatives.\n",
    "\n",
    "image=np.repeat(image[None,...],3,axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import pandas as pd\n",
    "import os\n",
    "from skimage import io\n",
    "import torch\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "from skimage import color\n",
    "\n",
    "# torchvision models are trained on input images normalized to [0 1] range .ToPILImage() function achives this\n",
    "# additional normalization is required see: http://pytorch.org/docs/master/torchvision/models.html\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize([256,256]),\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "\n",
    "validation_transform = transforms.Compose([\n",
    "        transforms.ToPILImage(),\n",
    "        transforms.Resize([256,256]),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])])\n",
    "\n",
    "class ChestXrayDataset_TL(Dataset):\n",
    "    \"\"\"Chest X-ray dataset from https://nihcc.app.box.com/v/ChestXray-NIHCC.\"\"\"\n",
    "\n",
    "    def __init__(self, csv_file, root_dir, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            csv_file (string): Path to the csv file filename information.\n",
    "            root_dir (string): Directory with all the images.\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.data_frame = pd.read_csv(csv_file)\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_frame)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_name = os.path.join(self.root_dir,\n",
    "                                self.data_frame.iloc[idx, 0])\n",
    "        \n",
    "        image = io.imread(img_name)\n",
    "        if len(image.shape) > 2 and image.shape[2] == 4:\n",
    "            image = image[:,:,0]\n",
    "            \n",
    "        image=np.repeat(image[None,...],3,axis=0)\n",
    "            \n",
    "        image_class = self.data_frame.iloc[idx, -1]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "            \n",
    "        sample = {'x': image, 'y': image_class}\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.2) (2 points)\n",
    "Define train, validation and test dataloaders loaders using the dataset class defined in Q.5.1.a and .csv files: HW2_TrainSet, HW2_ValidationSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.3) (2 points)\n",
    "Write the code for designing resnet34 architecture and loading the weights from ImageNet trained network. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.4) (4 points)\n",
    "Train the model for ~100 epochs and save the weights of the best model using the validation loss. Plot train and validation loss curves. Explain the learning behavior of training TL model as a feature extractor using the observations from loss/accuracy curves. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6) Analysis of the results from two networks trained on the full dataset (Total 8 points + max 10 points for Bonus Question)\n",
    "Use the validation loss to choose models from Q4 (model1) and Q5(model2) (These models are trained on the full dataset and they learned from train data and generalized well to the validation set). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1)  (4 Points)\n",
    "Using these models, plot confusion matrix and ROC curve for the disease classifier on the test set (HW2_TestSet.csv). Report AUC for this CNN model as the performance metric. You will have two confusion matrices and two ROC curves to compare model1 and model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is the place we predict the disease from a model trained, output for this function is \n",
    "#the target values and probabilty of each image having a disease \n",
    "\n",
    "# Example of how to plot ROC curves\n",
    "# https://stackoverflow.com/questions/25009284/how-to-plot-roc-curve-in-python\n",
    "\n",
    "# Example of how to calculate confusion matrix\n",
    "# https://www.kaggle.com/grfiv4/plot-a-confusion-matrix\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2) Understanding the network (4 points)\n",
    "Using the best performing model (choose the model using the analysis you performed on Q6.1), we will figure out where our network gathers infomation to decide the class for the image. One way of doing this is to occlude parts of the image and run through your network. By changing the location of the ocluded region we can visualize the probability of image being in one class as a 2-dimensional heat map. Using the best performing model, provide the heat map of the following images: HW2_visualize.csv. Do the heap map and bounding box for pathologies provide similar information? Describe your findings.\n",
    "Reference: https://arxiv.org/pdf/1311.2901.pdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# You can use the code from: https://github.com/thesemicolonguy/convisualize_nb/blob/master/cnn-visualize.ipynb \n",
    "# with minor modifications\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.3 ) Your CNN architecture design (Bonus Question Maximum 12 Points)\n",
    "Be creative and design your own CNN model. This model can be some variation of the baseline model using the information from hyperparameter search or it can be a totally new architecture. Use the knowledge you gained from previous questions to design your network. Because of this reason, your network is expected to provide superior results. After you trained your network on the whole train set, choose the best performaing model using the loss on the whole validation set. Provide the confusion matrix, ROC curves and macro AUC for your best performing model using the whole test set. Explain your design criteria and why your performance is better compared to the baseline model. Some architecture change suggestions: convolution filter dimensions, dilated convolutions, network without a fully connected layer, deeper networks, data augmentation ...     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
